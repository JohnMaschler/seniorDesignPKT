{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "\n",
    "        assert (\n",
    "            self.head_dim * heads == embed_size\n",
    "        ), \"Embedding size needs to be divisible by heads\"\n",
    "\n",
    "        self.values = nn.Linear(embed_size, embed_size)\n",
    "        self.keys = nn.Linear(embed_size, embed_size)\n",
    "        self.queries = nn.Linear(embed_size, embed_size)\n",
    "        self.fc_out = nn.Linear(embed_size, embed_size)\n",
    "\n",
    "    def forward(self, values, keys, query, mask):\n",
    "        # Get number of training examples\n",
    "        N = query.shape[0]\n",
    "\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], query.shape[1]\n",
    "\n",
    "        values = self.values(values)  # (N, value_len, embed_size)\n",
    "        keys = self.keys(keys)  # (N, key_len, embed_size)\n",
    "        queries = self.queries(query)  # (N, query_len, embed_size)\n",
    "\n",
    "        # Split the embedding into self.heads different pieces\n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "\n",
    "        # Einsum does matrix mult. for query*keys for each training example\n",
    "        # with every other training example, don't be confused by einsum\n",
    "        # it's just how I like doing matrix multiplication & bmm\n",
    "\n",
    "        energy = torch.einsum(\"nqhd,nkhd->nhqk\", [queries, keys])\n",
    "        # queries shape: (N, query_len, heads, heads_dim),\n",
    "        # keys shape: (N, key_len, heads, heads_dim)\n",
    "        # energy: (N, heads, query_len, key_len)\n",
    "\n",
    "        # Mask padded indices so their weights become 0\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        # Normalize energy values similarly to seq2seq + attention\n",
    "        # so that they sum to 1. Also divide by scaling factor for\n",
    "        # better stability\n",
    "        attention = torch.softmax(energy / (self.embed_size ** (1 / 2)), dim=3)\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "\n",
    "        out = torch.einsum(\"nhql,nlhd->nqhd\", [attention, values]).reshape(\n",
    "            N, query_len, self.heads * self.head_dim\n",
    "        )\n",
    "        # attention shape: (N, heads, query_len, key_len)\n",
    "        # values shape: (N, value_len, heads, heads_dim)\n",
    "        # out after matrix multiply: (N, query_len, heads, head_dim), then\n",
    "        # we reshape and flatten the last two dimensions.\n",
    "\n",
    "        out = self.fc_out(out)\n",
    "        # Linear layer doesn't modify the shape, final shape will be\n",
    "        # (N, query_len, embed_size)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion * embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * embed_size, embed_size),\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "\n",
    "        # Add skip connection, run through normalization and finally dropout\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        return out\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        device,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        max_length,\n",
    "    ):\n",
    "\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(src_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        out = self.dropout(\n",
    "            (self.word_embedding(x) + self.position_embedding(positions))\n",
    "        )\n",
    "\n",
    "        # In the Encoder the query, key, value are all the same, it's in the\n",
    "        # decoder this will change. This might look a bit odd in this case.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, forward_expansion, dropout, device):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.norm = nn.LayerNorm(embed_size)\n",
    "        self.attention = SelfAttention(embed_size, heads=heads)\n",
    "        self.transformer_block = TransformerBlock(\n",
    "            embed_size, heads, dropout, forward_expansion\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, value, key, src_mask, trg_mask):\n",
    "        attention = self.attention(x, x, x, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + x))\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        trg_vocab_size,\n",
    "        embed_size,\n",
    "        num_layers,\n",
    "        heads,\n",
    "        forward_expansion,\n",
    "        dropout,\n",
    "        device,\n",
    "        max_length,\n",
    "    ):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(trg_vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                DecoderBlock(embed_size, heads, forward_expansion, dropout, device)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.fc_out = nn.Linear(embed_size, trg_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_out, src_mask, trg_mask):\n",
    "        N, seq_length = x.shape\n",
    "        positions = torch.arange(0, seq_length).expand(N, seq_length).to(self.device)\n",
    "        x = self.dropout((self.word_embedding(x) + self.position_embedding(positions)))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        out = self.fc_out(x)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        src_vocab_size,\n",
    "        trg_vocab_size,\n",
    "        src_pad_idx,\n",
    "        trg_pad_idx,\n",
    "        embed_size=512,\n",
    "        num_layers=6,\n",
    "        forward_expansion=4,\n",
    "        heads=8,\n",
    "        dropout=0,\n",
    "        device=\"cpu\",\n",
    "        max_length=100,\n",
    "    ):\n",
    "\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        self.encoder = Encoder(\n",
    "            src_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            device,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.decoder = Decoder(\n",
    "            trg_vocab_size,\n",
    "            embed_size,\n",
    "            num_layers,\n",
    "            heads,\n",
    "            forward_expansion,\n",
    "            dropout,\n",
    "            device,\n",
    "            max_length,\n",
    "        )\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        # (N, 1, 1, src_len)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        N, trg_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_len, trg_len))).expand(\n",
    "            N, 1, trg_len, trg_len\n",
    "        )\n",
    "\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_src = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_src, src_mask, trg_mask)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data entry:\n",
      "{'input': 'Send a TCP packet from 192.168.229.254 (port 443) to 192.168.202.79 (port 46117), with flags PUSH,ACK and payload size 47 bytes.', 'output': {'src_ip': '192.168.229.254', 'dst_ip': '192.168.202.79', 'protocol': 'TCP', 'src_port': 443, 'dst_port': 46117, 'timestamp': 1331901000.0, 'flags': 'PUSH,ACK', 'payload_size': 47}}\n"
     ]
    }
   ],
   "source": [
    "with open(\"transformed_packets.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print(\"Sample data entry:\")\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "class TextTokenizer:\n",
    "    def __init__(self):\n",
    "        self.token_to_id = {\"<PAD>\": 0, \"<UNK>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n",
    "        self.id_to_token = {0: \"<PAD>\", 1: \"<UNK>\", 2: \"<SOS>\", 3: \"<EOS>\"}\n",
    "        self.vocab_size = 4  # starting count\n",
    "\n",
    "    def build_vocab(self, text_list):\n",
    "        # Split each text into tokens\n",
    "        for text in text_list:\n",
    "            for token in self.tokenize(text):\n",
    "                if token not in self.token_to_id:\n",
    "                    self.token_to_id[token] = self.vocab_size\n",
    "                    self.id_to_token[self.vocab_size] = token\n",
    "                    self.vocab_size += 1\n",
    "\n",
    "    def tokenize(self, text):\n",
    "        # Simple: split on non-alphanumeric\n",
    "        tokens = re.findall(r\"[A-Za-z0-9.]+\", text.lower())\n",
    "        return tokens\n",
    "\n",
    "    def encode(self, text):\n",
    "        # Add <SOS> at the start and <EOS> at the end\n",
    "        tokens = [self.token_to_id.get(t, self.token_to_id[\"<UNK>\"]) \n",
    "                  for t in self.tokenize(text)]\n",
    "        return [self.token_to_id[\"<SOS>\"]] + tokens + [self.token_to_id[\"<EOS>\"]]\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return [self.id_to_token.get(t, \"<UNK>\") for t in tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output packet is a dictionary like:\n",
    "# {\n",
    "#   \"src_ip\": \"192.168.202.79\",\n",
    "#   \"dst_ip\": \"192.168.229.254\",\n",
    "#   ...\n",
    "# }\n",
    "\n",
    "class PacketTokenizer:\n",
    "    def __init__(self):\n",
    "        self.token_to_id = {\"<PAD>\": 0, \"<UNK>\": 1, \"<SOS>\": 2, \"<EOS>\": 3}\n",
    "        self.id_to_token = {0: \"<PAD>\", 1: \"<UNK>\", 2: \"<SOS>\", 3: \"<EOS>\"}\n",
    "        self.vocab_size = 4  # starting count\n",
    "\n",
    "    def build_vocab(self, packets):\n",
    "        # Each packet is a dict of fields.\n",
    "        # We can combine \"key:value\" into a single token, or treat keys/values separately.\n",
    "        for packet in packets:\n",
    "            for key, value in packet.items():\n",
    "                token = f\"{key}:{value}\"\n",
    "                if token not in self.token_to_id:\n",
    "                    self.token_to_id[token] = self.vocab_size\n",
    "                    self.id_to_token[self.vocab_size] = token\n",
    "                    self.vocab_size += 1\n",
    "\n",
    "    def encode(self, packet_dict):\n",
    "        # Convert a dictionary to a list of tokens\n",
    "        tokens = []\n",
    "        for key, value in packet_dict.items():\n",
    "            token = f\"{key}:{value}\"\n",
    "            tokens.append(self.token_to_id.get(token, self.token_to_id[\"<UNK>\"]))\n",
    "        # Optionally add <SOS> and <EOS>\n",
    "        return [self.token_to_id[\"<SOS>\"]] + tokens + [self.token_to_id[\"<EOS>\"]]\n",
    "\n",
    "    def decode(self, token_ids):\n",
    "        return [self.id_to_token.get(t, \"<UNK>\") for t in token_ids]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text vocab size: 430\n",
      "Packet vocab size: 783\n"
     ]
    }
   ],
   "source": [
    "# Separate inputs (texts) and outputs (packet dicts)\n",
    "input_texts = [item[\"input\"] for item in data]\n",
    "output_packets = [item[\"output\"] for item in data]\n",
    "\n",
    "text_tokenizer = TextTokenizer()\n",
    "text_tokenizer.build_vocab(input_texts)\n",
    "\n",
    "packet_tokenizer = PacketTokenizer()\n",
    "packet_tokenizer.build_vocab(output_packets)\n",
    "\n",
    "print(\"Text vocab size:\", text_tokenizer.vocab_size)\n",
    "print(\"Packet vocab size:\", packet_tokenizer.vocab_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PacketDataset(Dataset):\n",
    "    def __init__(self, data, text_tokenizer, packet_tokenizer):\n",
    "        self.data = data\n",
    "        self.text_tokenizer = text_tokenizer\n",
    "        self.packet_tokenizer = packet_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        text = item[\"input\"]\n",
    "        packet = item[\"output\"]\n",
    "\n",
    "        # Encode text as source tokens\n",
    "        src = self.text_tokenizer.encode(text)\n",
    "\n",
    "        # Encode packet as target tokens\n",
    "        trg = self.packet_tokenizer.encode(packet)\n",
    "\n",
    "        return torch.tensor(src), torch.tensor(trg)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Separate src and trg from the batch\n",
    "    src_batch = [item[0] for item in batch]\n",
    "    trg_batch = [item[1] for item in batch]\n",
    "\n",
    "    # Pad sequences\n",
    "    src_padded = pad_sequence(src_batch, batch_first=True, padding_value=0)\n",
    "    trg_padded = pad_sequence(trg_batch, batch_first=True, padding_value=0)\n",
    "\n",
    "    return src_padded, trg_padded\n",
    "\n",
    "dataset = PacketDataset(data, text_tokenizer, packet_tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = text_tokenizer.vocab_size\n",
    "trg_vocab_size = packet_tokenizer.vocab_size\n",
    "src_pad_idx = text_tokenizer.token_to_id[\"<PAD>\"]\n",
    "trg_pad_idx = packet_tokenizer.token_to_id[\"<PAD>\"]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = Transformer(\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    trg_vocab_size=trg_vocab_size,\n",
    "    src_pad_idx=src_pad_idx,\n",
    "    trg_pad_idx=trg_pad_idx,\n",
    "    embed_size=128,\n",
    "    num_layers=2,\n",
    "    forward_expansion=2,\n",
    "    heads=2,\n",
    "    dropout=0.1,\n",
    "    device=device,\n",
    "    max_length=100\n",
    ").to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2 - Loss: 1.71501886844635\n",
      "Epoch 2/2 - Loss: 0.2676395773887634\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=trg_pad_idx)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "num_epochs = 2\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for src, trg in dataloader:\n",
    "        src, trg = src.to(device), trg.to(device)\n",
    "\n",
    "        # We'll use teacher forcing approach: feed trg[:, :-1] into the model\n",
    "        trg_input = trg[:, :-1]\n",
    "        trg_expected = trg[:, 1:]\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(src, trg_input)\n",
    "\n",
    "        # Reshape to compute loss\n",
    "        # output shape: (batch_size, seq_len, vocab_size)\n",
    "        # trg_expected shape: (batch_size, seq_len)\n",
    "        output = output.reshape(-1, output.shape[2])\n",
    "        trg_expected = trg_expected.reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg_expected)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Packet Tokens: ['src_ip:192.168.202.76', 'dst_ip:192.168.203.61', 'protocol:TCP', 'src_port:55554', 'dst_port:36694', 'timestamp:1331904607.97', 'flags:PUSH,ACK', 'payload_size:186']\n"
     ]
    }
   ],
   "source": [
    "def generate_packet(model, user_input_text, max_length=30):\n",
    "    model.eval()\n",
    "\n",
    "    # Encode user input with text_tokenizer\n",
    "    src = text_tokenizer.encode(user_input_text)\n",
    "    src_tensor = torch.tensor(src).unsqueeze(0).to(device)  # shape: (1, seq_len)\n",
    "\n",
    "    # Start token for target\n",
    "    trg_tokens = [packet_tokenizer.token_to_id[\"<SOS>\"]]\n",
    "    for _ in range(max_length):\n",
    "        trg_tensor = torch.tensor(trg_tokens).unsqueeze(0).to(device)  # (1, len_so_far)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "        \n",
    "        # output shape: (1, trg_len, vocab_size)\n",
    "        next_token = output[0, -1, :].argmax(dim=-1).item()\n",
    "        trg_tokens.append(next_token)\n",
    "        \n",
    "        # If <EOS> is generated, stop\n",
    "        if next_token == packet_tokenizer.token_to_id[\"<EOS>\"]:\n",
    "            break\n",
    "    \n",
    "    # Exclude the first <SOS> and last <EOS>\n",
    "    return trg_tokens[1:-1] if trg_tokens[-1] == packet_tokenizer.token_to_id[\"<EOS>\"] else trg_tokens[1:]\n",
    "\n",
    "user_text = \"payload size 186 bytes\"\n",
    "generated_token_ids = generate_packet(model, user_text)\n",
    "decoded_tokens = packet_tokenizer.decode(generated_token_ids)\n",
    "print(\"Generated Packet Tokens:\", decoded_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st attempt:\n",
    "message: \"flags push\"\n",
    "output: Generated Packet Tokens: ['src_ip:192.168.202.79', 'dst_ip:192.168.229.153', 'protocol:TCP', 'src_port:55173', 'dst_port:445', 'timestamp:1331901000.02', 'flags:PUSH,ACK', 'payload_size:138']\n",
    "\n",
    "\n",
    "\n",
    "2nd attempt:\n",
    "message: payload size 186 bytes\n",
    "message: Generated Packet Tokens: ['src_ip:192.168.202.76', 'dst_ip:192.168.203.61', 'protocol:TCP', 'src_port:55554', 'dst_port:36694', 'timestamp:1331904607.97', 'flags:PUSH,ACK', 'payload_size:186']\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
